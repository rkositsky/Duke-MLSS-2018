{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duke MLSS: Day 1\n",
    "\n",
    "Rachel Kositsky<br>\n",
    "2018-06-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:len(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in \"hello\":\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence comprehension\n",
    "lst = [i**2 for i in range(1,11)]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5]\n",
    "y = [4, 6, 7]\n",
    "\n",
    "# dot product\n",
    "z = [x[i]*y[i] for i in range(len(x))]\n",
    "z, sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, y):\n",
    "    assert(len(x) == len(y))\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nd-array = n-dimensional array\n",
    "# it's faster because it doesn't have to do checks\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f3fb4762b576>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/rachelkositsky/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/rachelkositsky/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/rachelkositsky/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/rachelkositsky/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/rachelkositsky/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Future:\n",
    "# train, test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(mnist.train.images)\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(784)\n",
    "# 28x28 images\n",
    "# 55k images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " '_',\n",
       " '_3',\n",
       " '_4',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i2',\n",
       " '_i3',\n",
       " '_i4',\n",
       " '_i5',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'input_data',\n",
       " 'mnist',\n",
       " 'np',\n",
       " 'plt',\n",
       " 'quit',\n",
       " 'tf',\n",
       " 'timeit']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at everything defined in namespace\n",
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "# Everything is 0 except for the position corresponding to the digit\n",
    "# e.g. image 0 is a 7\n",
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure of similarity of two images, unnormalized\n",
    "np.dot(mnist.train.images[0], mnist.train.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the norm\n",
    "a = np.array([1,2,3,4])\n",
    "#a = np.array([.8, .6])\n",
    "print(\"Norm of a:\", np.linalg.norm(a))\n",
    "print(\"Normalized a:\", a / np.linalg.norm(a))\n",
    "print(\"Norm of a after normalization:\", np.linalg.norm(a / np.linalg.norm(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the norm of each image\n",
    "image_norms = np.linalg.norm(mnist.train.images, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic broadcasting by column: repeat row three times: [[1,2,3], [1,2,3], [1,2,3]]\n",
    "# Divide each column by the array given\n",
    "m / np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Know the shape\n",
    "# repeat by columns three times: [[1,1,1], [2,2,2], [3,3,3]]\n",
    "m / np.array([1,2,3]).reshape([3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape -1: fill in\n",
    "np.array([1,2,3, 4, 5, 6]).reshape([2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to image norms\n",
    "# make it into a column, then divide\n",
    "image_norms.reshape([55000, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_images = mnist.train.images / image_norms.reshape([len(mnist.train.images), 1])\n",
    "normalized_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(normalized_images, axis=1)\n",
    "np.linalg.norm(normalized_images, axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression model using TensorFlow\n",
    "\n",
    "Can also get other, lower, accuracies using other ways\n",
    "\n",
    "Check class notes\n",
    "\n",
    "Idea of tensorflow: make a computational graph. Binary operations that lead to loss function.\n",
    "\n",
    "```\n",
    "b  m x  y\n",
    "\\  \\/  / \n",
    " \\ *  /\n",
    "  \\| /\n",
    "   + |\n",
    "   \\/\n",
    "   -\n",
    "   |\n",
    "   square\n",
    "   |\n",
    "   loss\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show(num):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(num.reshape(-1,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(mnist.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4697518],\n",
       "       [4.7063866],\n",
       "       [2.2834907],\n",
       "       ...,\n",
       "       [3.397404 ],\n",
       "       [2.6706285],\n",
       "       [7.976755 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.dot(normalized_images[-1].reshape([784, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The operations of this graph are empty\n",
    "tf.reset_default_graph()\n",
    "g = tf.get_default_graph()\n",
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal' type=Add>,\n",
       " <tf.Operation 'Variable' type=VariableV2>,\n",
       " <tf.Operation 'Variable/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable/read' type=Identity>,\n",
       " <tf.Operation 'truncated_normal_1/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal_1/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal_1/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal_1/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal_1/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal_1' type=Add>,\n",
       " <tf.Operation 'Variable_1' type=VariableV2>,\n",
       " <tf.Operation 'Variable_1/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_1/read' type=Identity>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'Add' type=Add>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/labels_stop_gradient' type=StopGradient>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Rank' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Shape' type=Shape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Rank_1' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Shape_1' type=Shape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Sub/y' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Sub' type=Sub>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice/begin' type=Pack>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice/size' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice' type=Slice>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/concat/values_0' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/concat/axis' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/concat' type=ConcatV2>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Reshape' type=Reshape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Rank_2' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Shape_2' type=Shape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Sub_1/y' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Sub_1' type=Sub>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice_1/begin' type=Pack>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice_1/size' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice_1' type=Slice>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/concat_1/values_0' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/concat_1/axis' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/concat_1' type=ConcatV2>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg' type=SoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Sub_2/y' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Sub_2' type=Sub>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice_2/begin' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice_2/size' type=Pack>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Slice_2' type=Slice>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits_sg/Reshape_2' type=Reshape>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Mean' type=Mean>,\n",
       " <tf.Operation 'gradients/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/grad_ys_0' type=Const>,\n",
       " <tf.Operation 'gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/LogSoftmax' type=LogSoftmax>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1/dim' type=Const>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_sg/Reshape_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'GradientDescent/learning_rate' type=Const>,\n",
       " <tf.Operation 'GradientDescent/update_Variable/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent/update_Variable_1/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add placeholder data. Something * 784 pixels.\n",
    "# Later: X = 100 images, etc.\n",
    "# Add weights and biases\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784]) # data\n",
    "y = tf.placeholder(tf.float32, [None, 10])  # labels\n",
    "W = tf.Variable(tf.truncated_normal([784, 10], stddev=0.1))  # weight\n",
    "b = tf.Variable(tf.truncated_normal([10], stddev=0.1)) # bias\n",
    "mult_result = tf.matmul(X, W)\n",
    "scores = tf.add(mult_result, b)\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=scores, labels=y)\n",
    "avg_loss = tf.reduce_mean(loss)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "# learning rate = 0.01. pass it the node that we want it to minimize: the loss node\n",
    "\n",
    "# To implement stochastic gradient descent, will feed in minibatches for X, y\n",
    "initialize_all = tf.global_variables_initializer()\n",
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 types of nodes that hold numbers:\n",
    "1. placeholders for data/label\n",
    "2. variables that are being updated every time the graph is run\n",
    "3. constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize every node in the graph by running node initialize_all\n",
    "sess.run(initialize_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7006936"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(avg_loss, feed_dict = {X: mnist.train.images[:100],\n",
    "                         y: mnist.train.labels[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.879731724872837"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.7) # 14.8% correct at random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do one step\n",
    "sess.run(train_step, feed_dict = {X: mnist.train.images[:100],\n",
    "                                  y: mnist.train.labels[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8420691"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(avg_loss, feed_dict = {X: mnist.train.images[:100],\n",
    "                         y: mnist.train.labels[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.115765537145876"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.84) # 17.1% correct after one train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run more\n",
    "batch_size = 100\n",
    "num_iters = int(len(mnist.train.images)/batch_size)\n",
    "for i in range(num_iters):\n",
    "    start = i*batch_size\n",
    "    end=(i+1)*batch_size\n",
    "    sess.run(train_step, feed_dict = {X: mnist.train.images[start:end],\n",
    "                                       y: mnist.train.labels[start:end]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3322853446006775\n",
      "Percent correct: 1.3941506147384644\n"
     ]
    }
   ],
   "source": [
    "test_loss = sess.run(avg_loss, feed_dict = {X: mnist.test.images,\n",
    "                         y: mnist.test.labels})\n",
    "print(\"Test loss: {}\\nPercent correct: {}\".format(test_loss, np.exp(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_scores = sess.run(scores, feed_dict = {X: mnist.test.images, y: mnist.test.labels})\n",
    "np.argmax(computed_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9074 right out of 10000 images = 90.74% accuracy\n"
     ]
    }
   ],
   "source": [
    "# See how many you get right\n",
    "computed_scores = sess.run(scores, feed_dict = {X: mnist.test.images, y: mnist.test.labels})\n",
    "num_test_corr = sum(np.argmax(computed_scores, axis=1) == np.argmax(mnist.test.labels, axis=1))\n",
    "num_test_images = len(mnist.test.labels)\n",
    "print(\"Got {} right out of {} images = {:2.2f}% accuracy\".format(num_test_corr, num_test_images, 100.0*num_test_corr/num_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 100 and 784 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,100], [784,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 100 and 784 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,100], [784,10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-1b080fa87426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmult_result2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mlatent_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmult_result2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2122\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4277\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4278\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4279\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4280\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4281\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 100 and 784 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,100], [784,10]."
     ]
    }
   ],
   "source": [
    "# The operations of this graph are empty\n",
    "tf.reset_default_graph()\n",
    "g = tf.get_default_graph()\n",
    "g.get_operations()\n",
    "\n",
    "# Add placeholder data. Something * 784 pixels.\n",
    "# Later: X = 100 images, etc.\n",
    "# Add weights and biases\n",
    "inner_units = 100\n",
    "X = tf.placeholder(tf.float32, [None, 784]) # data\n",
    "y = tf.placeholder(tf.float32, [None, 10])  # labels\n",
    "W = tf.Variable(tf.truncated_normal([784, inner_units], stddev=0.1))  # weight\n",
    "b = tf.Variable(tf.truncated_normal([inner_units], stddev=0.1)) # bias\n",
    "mult_result = tf.matmul(X, W)\n",
    "latent_scores = tf.add(mult_result, b)\n",
    "W2 = tf.Variable(tf.truncated_normal([784, 10], stddev=0.1))  # weight\n",
    "b2 = tf.Variable(tf.truncated_normal([10], stddev=0.1)) # bias\n",
    "mult_result2 = tf.matmul(latent_scores, W2)\n",
    "latent_scores = tf.add(mult_result2, b2)\n",
    "\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=scores, labels=y)\n",
    "avg_loss = tf.reduce_mean(loss)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "# learning rate = 0.01. pass it the node that we want it to minimize: the loss node\n",
    "\n",
    "# To implement stochastic gradient descent, will feed in minibatches for X, y\n",
    "initialize_all = tf.global_variables_initializer()\n",
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(7.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
