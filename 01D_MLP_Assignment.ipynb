{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Assignment: Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: Rachel Kositsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron\n",
    "\n",
    "Build a 2-layer MLP for MNIST digit classfication. Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image (784 dimensions) -> fully connected layer (500 hidden units)  -> nonlinearity (ReLU) -> fully connected layer (100 hidden units) -> nonlinearity (ReLU) -> fully connected (10 hidden units) -> softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Make sure to print out your accuracy on the test set at the end. => RK: got 97% accuracy after 50 rounds of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Placeholder_1' type=Placeholder>,\n",
       " <tf.Operation 'truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal' type=Add>,\n",
       " <tf.Operation 'Variable' type=VariableV2>,\n",
       " <tf.Operation 'Variable/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable/read' type=Identity>,\n",
       " <tf.Operation 'truncated_normal_1/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal_1/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal_1/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal_1/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal_1/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal_1' type=Add>,\n",
       " <tf.Operation 'Variable_1' type=VariableV2>,\n",
       " <tf.Operation 'Variable_1/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_1/read' type=Identity>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'Add' type=Add>,\n",
       " <tf.Operation 'Relu' type=Relu>,\n",
       " <tf.Operation 'truncated_normal_2/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal_2/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal_2/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal_2/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal_2/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal_2' type=Add>,\n",
       " <tf.Operation 'Variable_2' type=VariableV2>,\n",
       " <tf.Operation 'Variable_2/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_2/read' type=Identity>,\n",
       " <tf.Operation 'truncated_normal_3/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal_3/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal_3/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal_3/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal_3/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal_3' type=Add>,\n",
       " <tf.Operation 'Variable_3' type=VariableV2>,\n",
       " <tf.Operation 'Variable_3/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_3/read' type=Identity>,\n",
       " <tf.Operation 'MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'Add_1' type=Add>,\n",
       " <tf.Operation 'Relu_1' type=Relu>,\n",
       " <tf.Operation 'truncated_normal_4/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal_4/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal_4/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal_4/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal_4/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal_4' type=Add>,\n",
       " <tf.Operation 'Variable_4' type=VariableV2>,\n",
       " <tf.Operation 'Variable_4/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_4/read' type=Identity>,\n",
       " <tf.Operation 'truncated_normal_5/shape' type=Const>,\n",
       " <tf.Operation 'truncated_normal_5/mean' type=Const>,\n",
       " <tf.Operation 'truncated_normal_5/stddev' type=Const>,\n",
       " <tf.Operation 'truncated_normal_5/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'truncated_normal_5/mul' type=Mul>,\n",
       " <tf.Operation 'truncated_normal_5' type=Add>,\n",
       " <tf.Operation 'Variable_5' type=VariableV2>,\n",
       " <tf.Operation 'Variable_5/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable_5/read' type=Identity>,\n",
       " <tf.Operation 'MatMul_2' type=MatMul>,\n",
       " <tf.Operation 'Add_2' type=Add>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Rank' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Shape' type=Shape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Rank_1' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Shape_1' type=Shape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Sub/y' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Sub' type=Sub>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice/begin' type=Pack>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice/size' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice' type=Slice>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/concat/values_0' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/concat/axis' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/concat' type=ConcatV2>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Reshape' type=Reshape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Rank_2' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Shape_2' type=Shape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Sub_1/y' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Sub_1' type=Sub>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice_1/begin' type=Pack>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice_1/size' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice_1' type=Slice>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/concat_1/values_0' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/concat_1/axis' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/concat_1' type=ConcatV2>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits' type=SoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Sub_2/y' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Sub_2' type=Sub>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice_2/begin' type=Const>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice_2/size' type=Pack>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Slice_2' type=Slice>,\n",
       " <tf.Operation 'softmax_cross_entropy_with_logits/Reshape_2' type=Reshape>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Mean' type=Mean>,\n",
       " <tf.Operation 'gradients/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/grad_ys_0' type=Const>,\n",
       " <tf.Operation 'gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/Mean_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/Mean_grad/Shape_2' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'gradients/Mean_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'gradients/Mean_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/Mean_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'gradients/Mean_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax' type=LogSoftmax>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim' type=Const>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits/Reshape_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_2_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_2_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/Relu_1_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/Relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/Add_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/Add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/Add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/Add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/Add_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'GradientDescent/learning_rate' type=Const>,\n",
       " <tf.Operation 'GradientDescent/update_Variable/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent/update_Variable_1/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent/update_Variable_2/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent/update_Variable_3/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent/update_Variable_4/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent/update_Variable_5/ApplyGradientDescent' type=ApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create MLP\n",
    "tf.reset_default_graph()\n",
    "g = tf.get_default_graph()\n",
    "\n",
    "# Add placeholders for data and labels. Something * 784 pixels.\n",
    "# Later: X = 100 images, etc.\n",
    "X = tf.placeholder(tf.float32, [None, 784]) # data\n",
    "y = tf.placeholder(tf.float32, [None, 10])  # labels\n",
    "\n",
    "# Add variables for first layer\n",
    "num_hidden_units_1 = 500\n",
    "W1 = tf.Variable(tf.truncated_normal([784, num_hidden_units_1], stddev=0.1))  # weight\n",
    "b1 = tf.Variable(tf.truncated_normal([num_hidden_units_1], stddev=0.1)) # bias\n",
    "mult_result1 = tf.matmul(X, W1)\n",
    "latent_scores_1 = tf.add(mult_result1, b1)\n",
    "latent_relu_1 = tf.nn.relu(latent_scores_1)\n",
    "\n",
    "# Add variables for second layer\n",
    "num_hidden_units_2 = 256\n",
    "W2 = tf.Variable(tf.truncated_normal([num_hidden_units_1, num_hidden_units_2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.truncated_normal([num_hidden_units_2], stddev=0.1))\n",
    "mult_result2 = tf.matmul(latent_relu_1, W2)\n",
    "latent_scores_2 = tf.add(mult_result2, b2)\n",
    "latent_relu_2 = tf.nn.relu(latent_scores_2)\n",
    "\n",
    "# Add third layer with scores\n",
    "num_scores = 10\n",
    "W3 = tf.Variable(tf.truncated_normal([num_hidden_units_2, num_scores], stddev=0.1))\n",
    "b3 = tf.Variable(tf.truncated_normal([num_scores], stddev=0.1))\n",
    "mult_result3 = tf.matmul(latent_relu_2, W3)\n",
    "scores = tf.add(mult_result3, b3)\n",
    "\n",
    "# Add softmax loss calculation\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=scores, labels=y)\n",
    "avg_loss = tf.reduce_mean(loss)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(avg_loss)\n",
    "# learning rate = 0.01. pass it the node that we want it to minimize: the average loss node/the cross entropy\n",
    "\n",
    "# Initialization\n",
    "# To implement stochastic gradient descent, will feed in minibatches for X, y\n",
    "initialize_all = tf.global_variables_initializer()\n",
    "\n",
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:30<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(initialize_all)\n",
    "\n",
    "num_epochs = 50\n",
    "num_per_batch = 100 # divides 55000\n",
    "num_iters = int(len(mnist.train.images) / num_per_batch)\n",
    "for epoch in trange(num_epochs):\n",
    "    for i in range(num_iters):\n",
    "        start = i*num_per_batch\n",
    "        end = (i+1)*num_per_batch\n",
    "        sess.run(train_step, feed_dict = {X: mnist.train.images[start:end],\n",
    "                                          y: mnist.train.labels[start:end]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9737 right out of 10000 images = 97.37% accuracy\n"
     ]
    }
   ],
   "source": [
    "# See how many you get right\n",
    "computed_scores = sess.run(scores, feed_dict = {X: mnist.test.images, y: mnist.test.labels})\n",
    "num_test_corr = sum(np.argmax(computed_scores, axis=1) == np.argmax(mnist.test.labels, axis=1))\n",
    "num_test_images = len(mnist.test.labels)\n",
    "print(\"Got {} right out of {} images = {:2.2f}% accuracy\".format(num_test_corr, num_test_images, 100.0*num_test_corr/num_test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
